{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4820\n",
    "# Assignment 3: Understanding how a _feed-forward_ ANN works\n",
    "\n",
    "# Due: 2:00pm Sept 25, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On slide 28 of _ANN Intuition Part I_ slides, there is __an ANN of 1 input layer that takes 4 inputs, followed by 2 hidden layers with 3 neurons on each hidden layer, and finally 1 output layer with 4 neurons__.\n",
    "\n",
    "Feel free to choose values for the weights and thetas. Apparently, don't choose all zeros though.\n",
    "\n",
    "Feel free to choose activation functions on the hidden layers (e.g. sigmoid, relu, tanh...). However, make sure to use  __softmax__ on the output layer.\n",
    "\n",
    "Then, like what we did in Lab 4, in Section 0 below, manually calulate the outputs from all the neurons layer by layer. Then verify your calculatations using a TensorFlow/Teras model that you build in Section 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Manually calculate the outputs from all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "x_test = np.array([[0.2, 1.0, 0.6, 1.4]])\n",
    "\n",
    "weights_0 = np.array([[0, 1, 1, -1], \n",
    "                      [-1, 0, 1, 0], \n",
    "                      [0, -1, 1, -1]]).T\n",
    "\n",
    "#print(\"Weights:\\n\", weights_0)\n",
    "thetas_0 = np.full((3,), 0.01)\n",
    "#print(\"Thetas:\\n\", thetas_0)\n",
    "\n",
    "y_1 = tanh(x_test.dot(weights_0)+thetas_0)\n",
    "#print(\"y_1:\\n\", y_1)\n",
    "\n",
    "weights_1 = np.array([[-1, -1, -1], \n",
    "                      [0, 1, 1], \n",
    "                      [1, 1, 1]]).T\n",
    "\n",
    "#print(\"Weights:\\n\", weights_1)\n",
    "thetas_1 = np.full((3,), 0.1)\n",
    "#print(\"Thetas:\\n\", thetas_1)\n",
    "\n",
    "y_2 = sigmoid(np.dot(y_1, weights_1)+thetas_1)\n",
    "#print(\"y_2:\\n\", y_2)\n",
    "\n",
    "weights_2 = np.array([[0.3, 1, -0.67],\n",
    "                     [0.38, 0, -0.95],\n",
    "                     [0.43, 0, -0.34],\n",
    "                     [-0.56, -1, -0.98]]).T\n",
    "\n",
    "#print(\"Weights:\\n\", weights_2)\n",
    "thetas_2 = np.full((4,), 0.1)\n",
    "#print(\"Thetas:\\n\", thetas_2)\n",
    "\n",
    "#print(weights_0.shape, thetas_0.shape)\n",
    "#print(weights_1.shape, thetas_1.shape)\n",
    "#print(weights_2.shape, thetas_2.shape)\n",
    "\n",
    "output = softmax(tf.convert_to_tensor((np.dot(y_2, weights_2)+thetas_2))).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a model in Keras to verify the calculations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, input_shape=(4,), activation='tanh'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(Adam(lr=0.1),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.layers[0].set_weights([weights_0, thetas_0])\n",
    "model.layers[1].set_weights([weights_1, thetas_1])\n",
    "model.layers[2].set_weights([weights_2, thetas_2])\n",
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36802566 0.23201733 0.31242735 0.08752965]]\n",
      "[[0.36802572 0.23201734 0.31242737 0.08752966]]\n",
      "They match!\n"
     ]
    }
   ],
   "source": [
    "# Assuming \"output\" is the row matrix that has the final results of your manual calculations from Section 0 above\n",
    "print(output)\n",
    "# Assuming \"y_pred\" is the row matrix that has the final results of your ANN model from Section 1 above\n",
    "print(y_pred)\n",
    "\n",
    "if (np.isclose(y_pred, output).all()):\n",
    "    print(\"They match!\")\n",
    "else:\n",
    "    print(\"They don't match...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
