{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4820\n",
    "# Tutorial 10: MNIST - Convolutional Neural Network\n",
    "\n",
    "### Architecture\n",
    "\n",
    "In Tutorial 7, we treated pixels as features and used a fully-connected neural network to classify the images in the MNIST dataset.\n",
    "\n",
    "![Fully connected network to solve MNIST](./assets/mnist_fc.png)\n",
    "\n",
    "In this Tutorial, we are going to \n",
    "\n",
    "- Convolve the images using convolutional, pooling and activation layers that are stacked together, feeding the output of one layer into the input of the next. This stacking results in a feature-extraction pipeline that will gradually transform an image into a tensor with more channels and fewer pixels:\n",
    "\n",
    "![Convolutional stack](./assets/conv_stack.png)\n",
    "\n",
    "    The value of each \"pixel\" in the last feature map is influenced by a large regions of the original image and it will have learned to recognize complex patterns.\n",
    "    \n",
    "   > That's the beauty of stacking convolutional layers. The first layers will learn patterns of pixels in the original image, while deeper layers will learn more complex patterns that are combinations of the simpler patterns. \n",
    "   > \n",
    "   > In practice, early layers will specialize to recognize contrast lines in different orientations, while deeper layers will combine those contrast lines to identify parts of objects. The typical example of this is the face recognition task where middle layers recognize facial features like eyes, noses, and mouths while deeper nodes specialize on individual faces.\n",
    "   > \n",
    "   > The convolutional stack behaves like an optimized feature extraction pipeline that is trained to solve the task at hand optimally.\n",
    "\n",
    "- To complete the pipeline and solve the classification task we can pipe the output of the feature extraction pipeline into a fully connected final stack of layers.\n",
    "\n",
    "    We will need to unroll the output tensor into a long vector (as we did initially for the MNIST data) and connect this vector to the labels using a fully connected network.\n",
    "    \n",
    "    ![Flatten layer](./assets/flatten_fc.png)\n",
    "\n",
    "    We can also stack multiple fully connected layers if we want. Our final network is like a pancake of many layers, the convolutional part dealing with feature extraction and the fully connected part handling the classification.\n",
    "\n",
    "    The deeper we go in the network the richer and more unique are the patterns matched and so more robust the classification will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing images\n",
    "\n",
    "Let's load the data in first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# allow multiple outputs be displayed for each cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = X_train.astype('float32') / 255.0\n",
    "X_test_sc = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you all now, we need to reshape the data as order-4 tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train_sc.reshape(-1, 28, 28, 1)\n",
    "X_test_t = X_test_sc.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_t.shape\n",
    "X_test_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Tutorial 7, we also need to one-hot encode the multiclass output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "\n",
    "y_train_cat.shape\n",
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional network on images\n",
    "\n",
    "Let's now build a simple model with the following architecture:\n",
    "\n",
    "- A `Conv2D` layer with 32 filters of size 3x3.\n",
    "- A `MaxPooling2D` layer of size 2x2.\n",
    "- An activation layer with a `ReLU` activation function.\n",
    "- A couple of fully connected layers leading to the output of 10 classes corresponding to the digits.\n",
    "\n",
    "Notice that between the convolutional layers and the fully connected layers we will need `Flatten` to reshape the feature maps into feature vectors.\n",
    "\n",
    "To speed up the convergence, we initialize the convolutional weights drawing from a random normal distribution.\n",
    "\n",
    "Also notice that we need to pass `input_shape=(28, 28, 1)` to let the model know our input images are grayscale 28x28 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense\n",
    "\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1),\n",
    "                 kernel_initializer='normal'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: Why `Param # = 0` on the `max_pooling2d`, `activation`, and `flatten` layers?__\n",
    "\n",
    "__A:__ \n",
    "\n",
    "Because weights on these layers are all fixed instead of trained.\n",
    "\n",
    "__Q: Why `Output Shape = (None, 5408)` on the flatten layer?__\n",
    "\n",
    "__A:__ \n",
    "\n",
    "$5408 = 13*13*32$\n",
    "\n",
    "__Q: Why `Param # = 346176` in `dense` layer?__\n",
    "\n",
    "__A:__ \n",
    "\n",
    "$346176 = 5408*64+64$\n",
    "\n",
    "__Q: Why `Param # = 650` in `dense_1` layer?__\n",
    "\n",
    "__A:__ \n",
    "\n",
    "$650 = 64*10+10$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has 300k parameters, that's almost half of the fully connected model we designed in Tutorial 7. Let's train it for five epochs. Notice that we pass the tensor data we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(X_train_t, y_train_cat, batch_size=128,\n",
    "              epochs=5, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Tutorial 7, we can display the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = model.evaluate(X_train_t, y_train_cat,\n",
    "                           verbose=0)[1]\n",
    "test_acc = model.evaluate(X_test_t, y_test_cat,\n",
    "                          verbose=0)[1]\n",
    "\n",
    "print(\"Train accuracy: {:0.4f}\".format(train_acc))\n",
    "print(\"Test accuracy: {:0.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional model achieved a better performance on the MNIST data in fewer epochs. Overfitting also decreases, because the model is learning to combine spatial patterns instead of learning the exact values of the pixels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
