{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4820\n",
    "# Tutorial 5: Data Pre-processing and Model Analysis\n",
    "\n",
    "In the labs and assignments that have worked on so far, input data were pretty much all ready for training and testing our ANN models. However, in the real-world situation, that is not necessarily the case thus requiring a data pre-processing phase.\n",
    "\n",
    "Also, as shown in the *ANN Intuition Part II* slides, other than accurary, we want to use additional measurements such as ${f_1}$ score and confusion matrix to analyze the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. The *bank_customers* Dataset and Data Preprocessing\n",
    "\n",
    "> Libraries used: pandas, sklearn\n",
    "\n",
    "\n",
    "The *bank_customers* dataset contains information of 10,000 customers at a Bank. We want to build our ANN model to predict if a customer will leave the bank.\n",
    "\n",
    "For such a dataset, the data pro-processing phase primarily involves the following steps:\n",
    "\n",
    "- Some features such as row number, customer id and customer surname are irrelevant to our task therefore need to be removed from the dataset. \n",
    "- Some features such as geography and geneder need to be encoded into numerical values.\n",
    "- All features need to be scaled/standardized. \n",
    "\n",
    "> [Why, How and When to Scale your Features](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)\n",
    "\n",
    "\n",
    "It describes three species of 150 flowers, with four features each, so it’s a great example of a Multiclass classification. Let’s see how Multiclass classification’s done using Keras and the Iris dataset. First of all, let’s load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# allow multiple outputs be displayed for each cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('./data/bank_customers.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 First, let's remove the irrelevant information and seprate the input data from the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[:, 3:13].head(5)\n",
    "#df.iloc[:, 13].head(5)\n",
    "\n",
    "X = df.iloc[:, 3:13].values\n",
    "#X[:5,:]\n",
    "y = df.iloc[:, 13].values\n",
    "#y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Second, encode the categorical input darta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# country\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "#X[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "#X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3 Feature Scaling\n",
    "The standard score of a sample $x$ is calculated as:\n",
    "\n",
    "$$ z = (x - u) / s $$\n",
    "where $u$ is the mean of the training samples or zero if $with_mean=False$, and $s$ is the standard deviation of the training samples or one if `with_std=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/CS4820/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/envs/CS4820/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142, -0.90188624, -1.09598752,  0.29351742, -1.04175968,\n",
       "        -1.22584767, -0.91158349,  0.64609167,  0.97024255,  0.02188649],\n",
       "       [-0.44003595,  1.51506738, -1.09598752,  0.19816383, -1.38753759,\n",
       "         0.11735002, -0.91158349, -1.54776799,  0.97024255,  0.21653375],\n",
       "       [-1.53679418, -0.90188624, -1.09598752,  0.29351742,  1.03290776,\n",
       "         1.33305335,  2.52705662,  0.64609167, -1.03067011,  0.2406869 ],\n",
       "       [ 0.50152063, -0.90188624, -1.09598752,  0.00745665, -1.38753759,\n",
       "        -1.22584767,  0.80773656, -1.54776799, -1.03067011, -0.10891792],\n",
       "       [ 2.06388377,  1.51506738, -1.09598752,  0.38887101, -1.04175968,\n",
       "         0.7857279 , -0.91158349,  0.64609167,  0.97024255, -0.36527578]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.4 Splitting the dataset into the Training set and Test set\n",
    "\n",
    "Finally, we create a train and test split, with 20% test size. Notice that we introduce 2 more parameters:\n",
    "\n",
    "- `random_state = 0` sets the seed of the random number generator in a way that we all get the same results.\n",
    "- `stratify = y` to make sure that we preserve the ratio of labels in each set, i.e. we want each set to be composed of one third of each flower type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Binary-Classification Model\n",
    "\n",
    "> Libraries used: numpy, keras\n",
    "\n",
    "Now let's create an ANN model with:\n",
    "\n",
    "* 10 features in input (Credit Score, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HadCrCard, IsActiveMemeber, EstimatedSalary)\n",
    "* 2 hidden layers; 6 neurons per layer; ReLU activation\n",
    "* 1 neuron in output; sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "7200/7200 - 1s - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.4025 - val_accuracy: 0.8037\n",
      "Epoch 2/50\n",
      "7200/7200 - 0s - loss: 0.4273 - accuracy: 0.7979 - val_loss: 0.3980 - val_accuracy: 0.8213\n",
      "Epoch 3/50\n",
      "7200/7200 - 0s - loss: 0.4225 - accuracy: 0.8197 - val_loss: 0.3950 - val_accuracy: 0.8288\n",
      "Epoch 4/50\n",
      "7200/7200 - 1s - loss: 0.4198 - accuracy: 0.8276 - val_loss: 0.3959 - val_accuracy: 0.8375\n",
      "Epoch 5/50\n",
      "7200/7200 - 0s - loss: 0.4173 - accuracy: 0.8308 - val_loss: 0.3930 - val_accuracy: 0.8338\n",
      "Epoch 6/50\n",
      "7200/7200 - 0s - loss: 0.4150 - accuracy: 0.8318 - val_loss: 0.3942 - val_accuracy: 0.8413\n",
      "Epoch 7/50\n",
      "7200/7200 - 0s - loss: 0.4131 - accuracy: 0.8324 - val_loss: 0.3918 - val_accuracy: 0.8375\n",
      "Epoch 8/50\n",
      "7200/7200 - 1s - loss: 0.4117 - accuracy: 0.8326 - val_loss: 0.3949 - val_accuracy: 0.8413\n",
      "Epoch 9/50\n",
      "7200/7200 - 0s - loss: 0.4106 - accuracy: 0.8343 - val_loss: 0.3896 - val_accuracy: 0.8338\n",
      "Epoch 10/50\n",
      "7200/7200 - 1s - loss: 0.4092 - accuracy: 0.8329 - val_loss: 0.3924 - val_accuracy: 0.8425\n",
      "Epoch 11/50\n",
      "7200/7200 - 0s - loss: 0.4074 - accuracy: 0.8343 - val_loss: 0.3878 - val_accuracy: 0.8375\n",
      "Epoch 12/50\n",
      "7200/7200 - 1s - loss: 0.4069 - accuracy: 0.8353 - val_loss: 0.3877 - val_accuracy: 0.8388\n",
      "Epoch 13/50\n",
      "7200/7200 - 0s - loss: 0.4056 - accuracy: 0.8357 - val_loss: 0.3919 - val_accuracy: 0.8438\n",
      "Epoch 14/50\n",
      "7200/7200 - 0s - loss: 0.4058 - accuracy: 0.8350 - val_loss: 0.3887 - val_accuracy: 0.8475\n",
      "Epoch 15/50\n",
      "7200/7200 - 0s - loss: 0.4055 - accuracy: 0.8350 - val_loss: 0.3884 - val_accuracy: 0.8450\n",
      "Epoch 16/50\n",
      "7200/7200 - 1s - loss: 0.4044 - accuracy: 0.8349 - val_loss: 0.3880 - val_accuracy: 0.8438\n",
      "Epoch 17/50\n",
      "7200/7200 - 0s - loss: 0.4033 - accuracy: 0.8363 - val_loss: 0.3911 - val_accuracy: 0.8438\n",
      "Epoch 18/50\n",
      "7200/7200 - 0s - loss: 0.4034 - accuracy: 0.8340 - val_loss: 0.3880 - val_accuracy: 0.8413\n",
      "Epoch 19/50\n",
      "7200/7200 - 1s - loss: 0.4030 - accuracy: 0.8367 - val_loss: 0.3927 - val_accuracy: 0.8450\n",
      "Epoch 20/50\n",
      "7200/7200 - 1s - loss: 0.4026 - accuracy: 0.8349 - val_loss: 0.3882 - val_accuracy: 0.8462\n",
      "Epoch 21/50\n",
      "7200/7200 - 0s - loss: 0.4018 - accuracy: 0.8363 - val_loss: 0.3870 - val_accuracy: 0.8438\n",
      "Epoch 22/50\n",
      "7200/7200 - 0s - loss: 0.4013 - accuracy: 0.8335 - val_loss: 0.3859 - val_accuracy: 0.8388\n",
      "Epoch 23/50\n",
      "7200/7200 - 0s - loss: 0.4011 - accuracy: 0.8343 - val_loss: 0.3907 - val_accuracy: 0.8413\n",
      "Epoch 24/50\n",
      "7200/7200 - 1s - loss: 0.4016 - accuracy: 0.8356 - val_loss: 0.3932 - val_accuracy: 0.8350\n",
      "Epoch 25/50\n",
      "7200/7200 - 0s - loss: 0.4018 - accuracy: 0.8364 - val_loss: 0.3873 - val_accuracy: 0.8438\n",
      "Epoch 26/50\n",
      "7200/7200 - 0s - loss: 0.4006 - accuracy: 0.8343 - val_loss: 0.3916 - val_accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "7200/7200 - 1s - loss: 0.4001 - accuracy: 0.8367 - val_loss: 0.3922 - val_accuracy: 0.8400\n",
      "Epoch 28/50\n",
      "7200/7200 - 0s - loss: 0.4002 - accuracy: 0.8361 - val_loss: 0.3955 - val_accuracy: 0.8425\n",
      "Epoch 29/50\n",
      "7200/7200 - 0s - loss: 0.4003 - accuracy: 0.8349 - val_loss: 0.3828 - val_accuracy: 0.8413\n",
      "Epoch 30/50\n",
      "7200/7200 - 0s - loss: 0.3889 - accuracy: 0.8401 - val_loss: 0.3871 - val_accuracy: 0.8375\n",
      "Epoch 31/50\n",
      "7200/7200 - 0s - loss: 0.3769 - accuracy: 0.8442 - val_loss: 0.3687 - val_accuracy: 0.8550\n",
      "Epoch 32/50\n",
      "7200/7200 - 0s - loss: 0.3706 - accuracy: 0.8451 - val_loss: 0.3623 - val_accuracy: 0.8512\n",
      "Epoch 33/50\n",
      "7200/7200 - 0s - loss: 0.3642 - accuracy: 0.8485 - val_loss: 0.3642 - val_accuracy: 0.8525\n",
      "Epoch 34/50\n",
      "7200/7200 - 0s - loss: 0.3605 - accuracy: 0.8531 - val_loss: 0.3508 - val_accuracy: 0.8575\n",
      "Epoch 35/50\n",
      "7200/7200 - 0s - loss: 0.3574 - accuracy: 0.8549 - val_loss: 0.3571 - val_accuracy: 0.8562\n",
      "Epoch 36/50\n",
      "7200/7200 - 0s - loss: 0.3553 - accuracy: 0.8531 - val_loss: 0.3523 - val_accuracy: 0.8650\n",
      "Epoch 37/50\n",
      "7200/7200 - 0s - loss: 0.3537 - accuracy: 0.8522 - val_loss: 0.3560 - val_accuracy: 0.8587\n",
      "Epoch 38/50\n",
      "7200/7200 - 0s - loss: 0.3519 - accuracy: 0.8564 - val_loss: 0.3501 - val_accuracy: 0.8587\n",
      "Epoch 39/50\n",
      "7200/7200 - 0s - loss: 0.3494 - accuracy: 0.8553 - val_loss: 0.3466 - val_accuracy: 0.8612\n",
      "Epoch 40/50\n",
      "7200/7200 - 0s - loss: 0.3474 - accuracy: 0.8549 - val_loss: 0.3480 - val_accuracy: 0.8612\n",
      "Epoch 41/50\n",
      "7200/7200 - 0s - loss: 0.3463 - accuracy: 0.8585 - val_loss: 0.3488 - val_accuracy: 0.8650\n",
      "Epoch 42/50\n",
      "7200/7200 - 0s - loss: 0.3438 - accuracy: 0.8569 - val_loss: 0.3459 - val_accuracy: 0.8600\n",
      "Epoch 43/50\n",
      "7200/7200 - 0s - loss: 0.3416 - accuracy: 0.8606 - val_loss: 0.3551 - val_accuracy: 0.8600\n",
      "Epoch 44/50\n",
      "7200/7200 - 0s - loss: 0.3394 - accuracy: 0.8629 - val_loss: 0.3424 - val_accuracy: 0.8600\n",
      "Epoch 45/50\n",
      "7200/7200 - 0s - loss: 0.3379 - accuracy: 0.8615 - val_loss: 0.3404 - val_accuracy: 0.8625\n",
      "Epoch 46/50\n",
      "7200/7200 - 0s - loss: 0.3365 - accuracy: 0.8619 - val_loss: 0.3405 - val_accuracy: 0.8575\n",
      "Epoch 47/50\n",
      "7200/7200 - 0s - loss: 0.3359 - accuracy: 0.8658 - val_loss: 0.3425 - val_accuracy: 0.8675\n",
      "Epoch 48/50\n",
      "7200/7200 - 0s - loss: 0.3341 - accuracy: 0.8601 - val_loss: 0.3367 - val_accuracy: 0.8625\n",
      "Epoch 49/50\n",
      "7200/7200 - 0s - loss: 0.3333 - accuracy: 0.8636 - val_loss: 0.3455 - val_accuracy: 0.8637\n",
      "Epoch 50/50\n",
      "7200/7200 - 1s - loss: 0.3334 - accuracy: 0.8614 - val_loss: 0.3381 - val_accuracy: 0.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd2c27d1630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.1, batch_size = 10, epochs = 50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analysis\n",
    "\n",
    "> Libraries used: numpy, sklearn, matplotlib, seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our ANN model, which customers will leave? Which customers will stay? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a classification report, we'll run the `classification_report()` method, passing it the test class (the list that we created before of the _correct_ labels for each dataum) and the `y_pred_class` (the list we just obtained of the predicted classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1593\n",
      "           1       0.78      0.40      0.53       407\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2000\n",
      "   macro avg       0.82      0.69      0.72      2000\n",
      "weighted avg       0.85      0.86      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the confusion matrix by running the `confusion_matrix()` method passing it the same arguments as the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1547   46\n",
       "1   243  164"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cm, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our model did a reasonably good job when predicting which customers will stay (`y_pred=0`) but needed more imporvements when predicting which customers will stay (`y_pred=1`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
