{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS 4820\n",
    "# Assignment 4: Data Pre-processing and Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Pima Indians dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) is a very famous dataset distributed by UCI and originally collected from the National Institute of Diabetes and Digestive and Kidney Diseases. It contains data from clinical exams for women age 21 and above of Pima indian origins. The objective is to predict, based on diagnostic measurements, whether a patient has diabetes.\n",
    "\n",
    "It has the following features:\n",
    "\n",
    "- Pregnancies: Number of times pregnant\n",
    "- Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "- SkinThickness: Triceps skin fold thickness (mm)\n",
    "- Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "- BMI: Body mass index (weight in kg/(height in m)^2)\n",
    "- DiabetesPedigreeFunction: Diabetes pedigree function\n",
    "- Age: Age (years)\n",
    "\n",
    "The last column is the outcome, and it is a binary variable.\n",
    "\n",
    "In this first exercise we will explore it through the following steps:\n",
    "\n",
    "1. Load the ..data/diabetes.csv dataset, use `pandas` to explore the range of each feature\n",
    "- For each feature draw a histogram. Bonus points if you draw all the histograms in the same figure.\n",
    "- Explore correlations of features with the outcome column. You can do this in several ways, for example using the `sns.pairplot` we used above or drawing a heatmap of the correlations.\n",
    "- Do features need standardization? If so what standardization technique will you use? MinMax? Standard?\n",
    "- Prepare your final `X` and `y` variables to be used by an ML model. Make sure you define your target variable well. Will you need dummy columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Manually calculate the outputs from all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " [[0.9 1.2 0.7 0.8]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "X_test = np.array([[0.9,1.2,0.7,0.8]])\n",
    "print('Inputs:\\n', X_test, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights between input and hidden layer 1:\n",
      " [[ 1  0  0]\n",
      " [ 0  1 -1]\n",
      " [-1  0  0]\n",
      " [ 0 -1  1]]\n",
      "Thetas in hidden layer 1:\n",
      " [0.1 0.1 0.1]\n",
      "Outputs from hidden layer 1:\n",
      " [[ 0.29131261  0.46211716 -0.29131261]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,0,-1,0]]).T\n",
    "weights_0 = np.concatenate(\n",
    "    (\n",
    "        a,\n",
    "        np.roll(a,1,axis=0),\n",
    "        np.roll(a,3,axis=0)\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "thetas_0 = np.full((3,),0.1)\n",
    "print('Weights between input and hidden layer 1:\\n', weights_0)\n",
    "print('Thetas in hidden layer 1:\\n', thetas_0)\n",
    "\n",
    "y_1=tanh(X_test.dot(weights_0)+thetas_0)\n",
    "print('Outputs from hidden layer 1:\\n', y_1.numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights between hidden layer 1 and hidden layer 2:\n",
      " [[-1.  -0.8  1.3]\n",
      " [ 1.3 -1.  -0.8]\n",
      " [-0.8  1.3 -1. ]]\n",
      "Thetas in hidden layer 2:\n",
      " [0.1 0.1 0.1]\n",
      "Outputs from hidden layer 2:\n",
      " [[ 0.56659243 -0.7504016   0.38022725]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "b=np.array([[-1], [1.3], [-0.8]])\n",
    "weights_1 = np.concatenate(\n",
    "    (\n",
    "        b,\n",
    "        np.roll(b,1,axis=0),\n",
    "        np.roll(b,2,axis=0)\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "thetas_1 = np.full((3,),0.1)\n",
    "print('Weights between hidden layer 1 and hidden layer 2:\\n', weights_1)\n",
    "print('Thetas in hidden layer 2:\\n', thetas_1)\n",
    "\n",
    "y_2=tanh(y_1.numpy().dot(weights_1)+thetas_1)\n",
    "print('Outputs from hidden layer 2:\\n', y_2.numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights between hidden layer 2 and output layer:\n",
      " [[-1.   1.1  0.  -1. ]\n",
      " [ 0.  -1.   1.1  0. ]\n",
      " [ 1.1  0.  -1.   1.1]]\n",
      "Thetas in output layer:\n",
      " [0.1 0.1 0.1 0.1]\n",
      "Outputs from output layer:\n",
      " [[0.14432633 0.66121078 0.05013656 0.14432633]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c=np.array([[-1], [0], [1.1]])\n",
    "weights_2 = np.concatenate(\n",
    "    (\n",
    "        c,\n",
    "        np.roll(c,1,axis=0),\n",
    "        np.roll(c,2,axis=0),\n",
    "        np.roll(c,3,axis=0)\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "thetas_2 = np.full((4,),0.1)\n",
    "print('Weights between hidden layer 2 and output layer:\\n', weights_2)\n",
    "print('Thetas in output layer:\\n', thetas_2)\n",
    "\n",
    "output=Activation('softmax')(y_2.numpy().dot(weights_2)+thetas_2).numpy()\n",
    "\n",
    "#output = np.around(output.numpy(), decimals=3)\n",
    "print('Outputs from output layer:\\n', output, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a model in Keras to verify the calculations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape=(4,), activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(Adam(lr=0.1), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.,  0.,  0.],\n",
      "       [ 0.,  1., -1.],\n",
      "       [-1.,  0.,  0.],\n",
      "       [ 0., -1.,  1.]], dtype=float32), array([0.1, 0.1, 0.1], dtype=float32)]\n",
      "[array([[-1. , -0.8,  1.3],\n",
      "       [ 1.3, -1. , -0.8],\n",
      "       [-0.8,  1.3, -1. ]], dtype=float32), array([0.1, 0.1, 0.1], dtype=float32)]\n",
      "[array([[-1. ,  1.1,  0. , -1. ],\n",
      "       [ 0. , -1. ,  1.1,  0. ],\n",
      "       [ 1.1,  0. , -1. ,  1.1]], dtype=float32), array([0.1, 0.1, 0.1, 0.1], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].set_weights([weights_0, thetas_0])\n",
    "#model.layers[1].set_weights([np.ones((3, 3)), np.zeros((3,))])\n",
    "print(model.layers[0].get_weights())\n",
    "\n",
    "model.layers[1].set_weights([weights_1, thetas_1])\n",
    "print(model.layers[1].get_weights())\n",
    "\n",
    "model.layers[2].set_weights([weights_2, thetas_2])\n",
    "print(model.layers[2].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14432633 0.66121083 0.05013655 0.14432633]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#y_pred = np.around(y_pred, decimals=3)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14432633 0.66121083 0.05013655 0.14432633]]\n",
      "[[0.14432633 0.66121078 0.05013656 0.14432633]]\n",
      "They match!\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(output)\n",
    "if (np.isclose(y_pred, output).all()):\n",
    "    print(\"They match!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
